{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Training & Validation Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.feature\n",
    "\n",
    "classes = [\"adult_males\", \"subadult_males\", \"adult_females\", \"juveniles\", \"pups\"]\n",
    "patch_df = pd.DataFrame( columns=classes)\n",
    "val_patch_df = pd.DataFrame( columns=classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set your data path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data path (from Kaggle)\n",
    "train_path = 'Train/'\n",
    "# Train Dotted data path (from Kaggle)\n",
    "train_dot_path = 'TrainDotted/'\n",
    "\n",
    "# New images data path for sea_lion\n",
    "sea_lion_path = '300x300/sea_lion/'\n",
    "# New images data path for background\n",
    "background_path = '300x300/background/'\n",
    "\n",
    "r = 1     #scale down\n",
    "width = 300 #patch size\n",
    "\n",
    "train_nb = 947\n",
    "bad_train_ids = {\n",
    "            3, 7, 9, 21, 30, 34, 71, 81, 89, 97, 151, 184, 215, 234, 242, \n",
    "            268, 290, 311, 331, 344, 380, 384, 406, 421, 469, 475, 490, 499, \n",
    "            507, 530, 531, 605, 607, 614, 621, 638, 644, 687, 712, 721, 767, \n",
    "            779, 781, 794, 800, 811, 839, 840, 869, 882, 901, 903, 905, 909, \n",
    "            913, 927, 946}\n",
    "\n",
    "tids = range(0, train_nb)\n",
    "tids = list(set(tids) - bad_train_ids)\n",
    "tids.sort() \n",
    "\n",
    "\n",
    "filenames = [str(x)+'.jpg' for x in tids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.jpg\n",
      "20.jpg\n",
      "40.jpg\n",
      "60.jpg\n",
      "80.jpg\n",
      "100.jpg\n",
      "120.jpg\n",
      "140.jpg\n",
      "160.jpg\n",
      "180.jpg\n",
      "200.jpg\n",
      "220.jpg\n",
      "240.jpg\n",
      "260.jpg\n",
      "280.jpg\n",
      "300.jpg\n",
      "320.jpg\n",
      "340.jpg\n",
      "360.jpg\n",
      "400.jpg\n",
      "420.jpg\n",
      "440.jpg\n",
      "460.jpg\n",
      "480.jpg\n",
      "500.jpg\n",
      "520.jpg\n",
      "540.jpg\n",
      "560.jpg\n",
      "580.jpg\n",
      "600.jpg\n",
      "620.jpg\n",
      "640.jpg\n",
      "660.jpg\n",
      "680.jpg\n",
      "700.jpg\n",
      "720.jpg\n",
      "740.jpg\n",
      "760.jpg\n",
      "780.jpg\n",
      "820.jpg\n",
      "860.jpg\n",
      "880.jpg\n",
      "900.jpg\n",
      "920.jpg\n",
      "940.jpg\n"
     ]
    }
   ],
   "source": [
    "sea_lion_0 = 0\n",
    "sea_lion_1 = 0\n",
    "\n",
    "for filename in filenames:\n",
    "    \n",
    "    if int(filename[:-4])%20 == 0:\n",
    "        print(filename)\n",
    "    np_0 = np.array([0,0,0,0,0])\n",
    "    \n",
    "    \n",
    "    filename_number = filename[:-4]\n",
    "\n",
    "    \n",
    "    # read the Train and Train Dotted images\n",
    "    image_1 = cv2.imread(train_dot_path + filename)\n",
    "    image_2 = cv2.imread(train_path + filename)\n",
    "    img1 = cv2.GaussianBlur(image_1,(5,5),0)\n",
    "\n",
    "    # absolute difference between Train and Train Dotted\n",
    "    image_3 = cv2.absdiff(image_1,image_2)\n",
    "    mask_1 = cv2.cvtColor(image_1, cv2.COLOR_BGR2GRAY)\n",
    "    mask_1[mask_1 < 50] = 0\n",
    "    mask_1[mask_1 > 0] = 255\n",
    "    image_4 = cv2.bitwise_or(image_3, image_3, mask=mask_1)\n",
    "\n",
    "    # convert to grayscale to be accepted by skimage.feature.blob_log\n",
    "    image_6 = np.max(image_4,axis=2)\n",
    "\n",
    "    # detect blobs\n",
    "    blobs = skimage.feature.blob_log(image_6, min_sigma=3, max_sigma=7, num_sigma=1, threshold=0.05)\n",
    "\n",
    "    h,w,d = image_2.shape\n",
    "\n",
    "    res=np.zeros((int((w*r)//width)+1,int((h*r)//width)+1,5), dtype='int16')\n",
    "\n",
    "    for blob in blobs:\n",
    "        # get the coordinates for each blob\n",
    "        y, x, s = blob\n",
    "        # get the color of the pixel from Train Dotted in the center of the blob\n",
    "        b,g,R = img1[int(y)][int(x)][:]\n",
    "        x1 = int((x*r)//width)\n",
    "        y1 = int((y*r)//width)\n",
    "        # decision tree to pick the class of the blob by looking at the color in Train Dotted\n",
    "        if R > 225 and b < 25 and g < 25: # RED\n",
    "            res[x1,y1,0]+=1\n",
    "        elif R > 225 and b > 225 and g < 25: # MAGENTA\n",
    "            res[x1,y1,1]+=1\n",
    "        elif R < 75 and b < 50 and 150 < g < 200: # GREEN\n",
    "            res[x1,y1,4]+=1\n",
    "        elif R < 75 and  150 < b < 200 and g < 75: # BLUE\n",
    "            res[x1,y1,3]+=1\n",
    "        elif 60 < R < 120 and b < 50 and g < 75:  # BROWN\n",
    "            res[x1,y1,2]+=1\n",
    "\n",
    "    ma = cv2.cvtColor((1*(np.sum(image_1, axis=2)>20)).astype('uint8'), cv2.COLOR_GRAY2BGR)\n",
    "    img = cv2.resize(image_2 * ma, (int(w*r),int(h*r)))\n",
    "    h1,w1,d = img.shape\n",
    "\n",
    "    #trainX = []\n",
    "    #trainY = []\n",
    "\n",
    "    for i in range(int(w1//width)):\n",
    "        for j in range(int(h1//width)):\n",
    "            \n",
    "            # 703 is the number of validation data set for sea lions 5% of all the sea lions images\n",
    "            if np.sum(res[i,j,:]) >0 and sea_lion_1 <=703:\n",
    "                val_patch_df.loc[sea_lion_path + filename_number + '_x' + str(i) + '_y' + str(j) + '.jpg'] = res[i,j,:]\n",
    "                sea_lion_1 += 1\n",
    "                \n",
    "            # 14064 is the number of training data set for sea lions 95% of all the sea lions images\n",
    "            elif np.sum(res[i,j,:]) >0 and sea_lion_1 <=14064:\n",
    "                patch_df.loc[sea_lion_path + filename_number + '_x' + str(i) + '_y' + str(j) + '.jpg'] = res[i,j,:]\n",
    "                sea_lion_1 += 1\n",
    "            \n",
    "            # 2110 is the number of validation data set for background 5% of all the background images\n",
    "            elif np.sum(res[i,j,:]) == 0 and sea_lion_0 <=2110:\n",
    "                val_patch_df.loc[background_path + filename_number + '_x' + str(i) + '_y' + str(j) + '.jpg'] = res[i,j,:]\n",
    "                sea_lion_0 += 1\n",
    "                \n",
    "            # 14064 is the number of training data set for background 95% of all the background images\n",
    "            elif np.sum(res[i,j,:]) == 0 and sea_lion_0 <=14064*3:\n",
    "                patch_df.loc[background_path + filename_number + '_x' + str(i) + '_y' + str(j) + '.jpg'] = res[i,j,:]\n",
    "                sea_lion_0 += 1\n",
    "\n",
    "            #trainX.append(img[j*width:j*width+width,i*width:i*width+width,:])\n",
    "            \n",
    "            \n",
    "            \n",
    "    for i in range(int(w//width)):\n",
    "        for j in range(int(h//width)):\n",
    "            #print(res[i,j,:])\n",
    "            if (res[i,j,:]== np_0).all():\n",
    "                img = image_2[j*width:j*width+width,i*width:i*width+width]\n",
    "                cv2.imwrite(background_path + filename_number + '_x' + str(i) + '_y' + str(j) + '.jpg', img)\n",
    "                \n",
    "            else:\n",
    "                img = image_2[j*width:j*width+width,i*width:i*width+width]\n",
    "                cv2.imwrite(sea_lion_path + filename_number + '_x' + str(i) + '_y' + str(j) + '.jpg', img)\n",
    "                \n",
    "\n",
    "def rmse(predictions, targets):\n",
    "    return np.sqrt(((predictions - targets) ** 2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40082"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(patch_df.sum(axis=1)[:]==0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_df.to_csv('divide_image.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_patch_df.to_csv('val_image.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
