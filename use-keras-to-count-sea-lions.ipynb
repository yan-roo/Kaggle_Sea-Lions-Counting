{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_active": false,
    "_cell_guid": "e29888aa-8eb8-e86c-f7ea-335b3721bcfa",
    "_uuid": "8637295fd48b02cc36592459e72ac525ebbeee76"
   },
   "source": [
    "# **Use keras to count Sea Lions**\n",
    "\n",
    "implement @outrunner method\n",
    "\n",
    "[Thanks to @outrunner(The 1st place winner)<br>for more information...][1]\n",
    "\n",
    "\n",
    "  [1]: https://www.kaggle.com/c/noaa-fisheries-steller-sea-lion-population-count/discussion/35408"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_active": false,
    "_cell_guid": "6ebfb9d2-30a4-2a86-ee32-8199c410d84c",
    "_execution_state": "idle",
    "_uuid": "367a29f6cf2e4f9bb3ed97148520b9de537e9242"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/yanroo/anaconda3/envs/Keras/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/yanroo/anaconda3/envs/Keras/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/yanroo/anaconda3/envs/Keras/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/yanroo/anaconda3/envs/Keras/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/yanroo/anaconda3/envs/Keras/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/yanroo/anaconda3/envs/Keras/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/yanroo/anaconda3/envs/Keras/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/yanroo/anaconda3/envs/Keras/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/yanroo/anaconda3/envs/Keras/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/yanroo/anaconda3/envs/Keras/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/yanroo/anaconda3/envs/Keras/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/yanroo/anaconda3/envs/Keras/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.feature\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "import pandas as pd\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "fdca7b86-a47f-46d5-9778-48449a682035",
    "_execution_state": "idle",
    "_uuid": "83ab09b6a18d1ec3f13bc5a166d222b82b98d257"
   },
   "source": [
    "**Scale and patch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_active": false,
    "_cell_guid": "f988a32b-f725-3a21-2ae1-64ad6b8b140d",
    "_execution_state": "idle",
    "_uuid": "da12d4183701191cb6f25144750152a17447bdd5"
   },
   "outputs": [],
   "source": [
    "r = 1     #scale down\n",
    "width = 300 #patch size \n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ignore Mismatched Images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_ignore_list():\n",
    "    df_ignore= pd.read_csv('./MismatchedTrainImages.txt')\n",
    "    ignore_list= df_ignore['train_id'].tolist()\n",
    "    \n",
    "    return ignore_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_active": false,
    "_cell_guid": "155679de-9f9b-5e2b-a0ca-914e65bdea29",
    "_uuid": "0cd131409ffa821e90d063c119edf27b49ef538d"
   },
   "source": [
    "**Get dot coordinates and cut image to patches :** (thanks to Radu Stoicescu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_active": false,
    "_cell_guid": "6e343a6d-c109-2f3c-10ba-ab218a95c8de",
    "_execution_state": "idle",
    "_uuid": "f8c46f4c18f7026255158bbdfcfb6dd879d271c0"
   },
   "outputs": [],
   "source": [
    "# def GetData(directory):\n",
    "#     trainX = []\n",
    "#     trainY = []\n",
    "#     no_sealionX = []\n",
    "#     no_sealionY = []\n",
    "#     ignore_list = read_ignore_list()\n",
    "#     img_count = 0\n",
    "    \n",
    "#     for i in range(10):\n",
    "#         if i in ignore_list:\n",
    "#             print(i)\n",
    "#             continue\n",
    "#         # read the Train and Train Dotted images\n",
    "#         image_1 = cv2.imread(\"./TrainDotted/\" + str(i)+ '.jpg')\n",
    "#         image_2 = cv2.imread(\"./Train/\" + str(i)+ '.jpg')\n",
    "#         img1 = cv2.GaussianBlur(image_1,(5,5),0)\n",
    "#         if image_1.shape != image_2.shape:\n",
    "#             print(i)\n",
    "#             image_2 = np.rot90(image_2, k=3)\n",
    "\n",
    "\n",
    "#         # absolute difference between Train and Train Dotted\n",
    "#         image_3 = cv2.absdiff(image_1,image_2)\n",
    "#         mask_1 = cv2.cvtColor(image_1, cv2.COLOR_BGR2GRAY)\n",
    "#         mask_1[mask_1 < 50] = 0\n",
    "#         mask_1[mask_1 > 0] = 255\n",
    "#         image_4 = cv2.bitwise_or(image_3, image_3, mask=mask_1)\n",
    "\n",
    "#         # convert to grayscale to be accepted by skimage.feature.blob_log\n",
    "#         image_6 = np.max(image_4,axis=2)\n",
    "\n",
    "#         # detect blobs\n",
    "#         blobs = skimage.feature.blob_log(image_6, min_sigma=3, max_sigma=7, num_sigma=1, threshold=0.05)\n",
    "\n",
    "#         h,w,d = image_2.shape\n",
    "\n",
    "#         res=np.zeros((int((w*r)//width)+1,int((h*r)//width)+1,5), dtype='int16')\n",
    "\n",
    "#         for blob in blobs:\n",
    "#             # get the coordinates for each blob\n",
    "#             y, x, s = blob\n",
    "#             # get the color of the pixel from Train Dotted in the center of the blob\n",
    "#             b,g,R = img1[int(y)][int(x)][:]\n",
    "#             x1 = int((x*r)//width)\n",
    "#             y1 = int((y*r)//width)\n",
    "#             # decision tree to pick the class of the blob by looking at the color in Train Dotted\n",
    "#             if R > 225 and b < 25 and g < 25: # RED\n",
    "#                 res[x1,y1,0]+=1\n",
    "#             elif R > 225 and b > 225 and g < 25: # MAGENTA\n",
    "#                 res[x1,y1,1]+=1\n",
    "#             elif R < 75 and b < 50 and 150 < g < 200: # GREEN\n",
    "#                 res[x1,y1,4]+=1\n",
    "#             elif R < 75 and  150 < b < 200 and g < 75: # BLUE\n",
    "#                 res[x1,y1,3]+=1\n",
    "#             elif 60 < R < 120 and b < 50 and g < 75:  # BROWN\n",
    "#                 res[x1,y1,2]+=1\n",
    "\n",
    "#         ma = cv2.cvtColor((1*(np.sum(image_1, axis=2)>20)).astype('uint8'), cv2.COLOR_GRAY2BGR)\n",
    "#         img = cv2.resize(image_2 * ma, (int(w*r),int(h*r)))\n",
    "#         h1,w1,d = img.shape\n",
    "\n",
    "#         for i in range(int(w1//width)):\n",
    "#             for j in range(int(h1//width)):\n",
    "#                 if np.sum(res[i,j,:]) >0:\n",
    "#                     trainY.append(res[i,j,:])\n",
    "#                     trainX.append(img[j*width:j*width+width,i*width:i*width+width,:])\n",
    "#                     img_count += 1\n",
    "#                 else:\n",
    "#                     no_sealionY.append(res[i,j,:])\n",
    "#                     no_sealionX.append(img[j*width:j*width+width,i*width:i*width+width,:])\n",
    "        \n",
    "#         if img_count >=5000:\n",
    "#             return np.array(trainX), np.array(trainY), np.array(no_sealionX), np.array(no_sealionY)\n",
    "\n",
    "#     return np.array(trainX), np.array(trainY), np.array(no_sealionX), np.array(no_sealionY)\n",
    "\n",
    "# def rmse(predictions, targets):\n",
    "#     return np.sqrt(((predictions - targets) ** 2).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_active": false,
    "_cell_guid": "1233be31-b216-19e3-e61b-9fb6f5cb8e30",
    "_uuid": "4884873c2988fd3559027ae649085452287e33bd"
   },
   "source": [
    "**Use only 1 image, split to train/test.**\n",
    "\n",
    "In my real approach:\n",
    "\n",
    " - r = 1 to 0.6561 (0.9^0, 0.9^1 ... 0.9^4)\n",
    "   \n",
    " - patch size = 300x300\n",
    "   \n",
    " - cut whole training set to patches, number of positive(all) vs\n",
    "   background(random) = 1 : 3\n",
    "   \n",
    " - 95% for training, 5% for validation\n",
    "\n",
    " - data augmentation by flip, rotate, change saturation, brightness, contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_active": false,
    "_cell_guid": "fcf3edc8-c64f-cf4e-d0dd-a58329f6f7b9",
    "_execution_state": "idle",
    "_uuid": "c85cb08f407de25a913de27b7d2d1c11f728cf60",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# trainX, trainY, BGX, BGY = GetData(\"./Train\")\n",
    "\n",
    "# print(trainY.shape, trainY[0])\n",
    "\n",
    "# np.random.seed(1004)\n",
    "# randomize = np.arange(len(trainX))\n",
    "# np.random.shuffle(randomize)\n",
    "\n",
    "# trainX = trainX[randomize]\n",
    "# trainY = trainY[randomize]\n",
    "\n",
    "# n_train = int(len(trainX) * 0.95)\n",
    "# valX = trainX[n_train:]\n",
    "# valY = trainY[n_train:]\n",
    "# trainX = trainX[:n_train]\n",
    "# trainY = trainY[:n_train]\n",
    "\n",
    "\n",
    "\n",
    "# randomize = np.arange(len(BGX))\n",
    "# np.random.shuffle(randomize)\n",
    "\n",
    "# BGX = BGX[randomize]\n",
    "# BGY = BGY[randomize]\n",
    "\n",
    "# trainX = np.concatenate((trainX, BGX[:9500]))\n",
    "# trainY = np.concatenate((trainY, BGY[:9500]))\n",
    "# valX = np.concatenate((valX, BGX[9500:10000]))\n",
    "# valY = np.concatenate((valY, BGY[9500:10000]))\n",
    "\n",
    "# # n_train = int(len(trainX) * 0.95)\n",
    "# # valX = trainX[n_train:]\n",
    "# # valY = trainY[n_train:]\n",
    "# # trainX = trainX[:n_train]\n",
    "# # trainY = trainY[:n_train]\n",
    "\n",
    "# print(trainY.shape, trainY[0])\n",
    "# print(valY.shape, valY[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del BGX\n",
    "# del BGY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Augmentation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yanroo/anaconda3/envs/Keras/lib/python3.6/site-packages/imgaug/imgaug.py:182: DeprecationWarning: Function `ContrastNormalization()` is deprecated. Use `imgaug.contrast.LinearContrast` instead.\n",
      "  warn_deprecated(msg, stacklevel=3)\n"
     ]
    }
   ],
   "source": [
    "from imgaug import augmenters as iaa\n",
    "\n",
    "augmentation = iaa.Sequential([\n",
    "    iaa.Fliplr(0.5), # horizontal flips\n",
    "    iaa.Flipud(0.5), # vertical flips\n",
    "\n",
    "    # Strengthen or weaken the contrast in each image.\n",
    "    iaa.ContrastNormalization((0.75, 1.5)),\n",
    "    #iaa.MultiplySaturation((0.5, 1.5)),\n",
    "    iaa.Multiply((0.8, 1.2), per_channel=0),\n",
    "    # Apply affine transformations to each image.\n",
    "    # Scale/zoom them, translate/move them, rotate them and shear them.\n",
    "    iaa.Affine(\n",
    "      scale = [1, 0.9, 0.81, 0.73, 0.66],\n",
    "        rotate=[90, 180, 270])\n",
    "    ], random_order=True) # apply augmenters in random order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('divide_image.csv')\n",
    "val_df = pd.read_csv('val_image.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 53442 validated image filenames.\n",
      "Found 2815 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "\n",
    "# preprocessing image and divide validaiton set\n",
    "train_datagen=ImageDataGenerator(preprocessing_function=augmentation.augment_image)\n",
    "validation_datagen=ImageDataGenerator()\n",
    "\n",
    "\n",
    "train_generator=train_datagen.flow_from_dataframe(train_df, \n",
    "                                                  directory='./',\n",
    "                                                  x_col=\"filename\",\n",
    "                                                  y_col=[\"adult_males\", \"subadult_males\", \"adult_females\", \"juveniles\", \"pups\"],               \n",
    "                                                  target_size=(300, 300),\n",
    "                                                  batch_size=batch_size,\n",
    "                                                  class_mode='other',\n",
    "                                                  shuffle=True)\n",
    "\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_dataframe(val_df,\n",
    "                                               directory='./',\n",
    "                                               x_col=\"filename\",\n",
    "                                               y_col=[\"adult_males\", \"subadult_males\", \"adult_females\", \"juveniles\", \"pups\"],               \n",
    "                                               target_size=(300, 300),\n",
    "                                               batch_size=batch_size,\n",
    "                                               class_mode='other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "# from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "\n",
    "# # preprocessing image and divide validaiton set\n",
    "# train_datagen=ImageDataGenerator(preprocessing_function=augmentation.augment_image)\n",
    "# validation_datagen=ImageDataGenerator()\n",
    "\n",
    "# train_generator=train_datagen.flow(trainX, \n",
    "#                                    trainY,\n",
    "#                                    batch_size=batch_size,\n",
    "#                                    shuffle=True)\n",
    "\n",
    "\n",
    "# validation_generator = validation_datagen.flow(valX, \n",
    "#                                    valY,\n",
    "#                                    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_active": false,
    "_cell_guid": "8ad7f45a-e8b6-d63d-d781-8499574bf167",
    "_uuid": "cc0e989a461c29dd6bc732b29b86ef08d55239fc"
   },
   "source": [
    "**Patches looks like :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_active": false,
    "_cell_guid": "2838a615-57f2-6eae-1b75-c80ec3422941",
    "_execution_state": "idle",
    "_uuid": "cf67e28d99778598876e6b7263148d8d2c3bd9dd"
   },
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(12,12))\n",
    "# for i in range(4):\n",
    "#     ax = fig.add_subplot(1,4,i+1)\n",
    "#     plt.imshow(cv2.cvtColor(trainX[i], cv2.COLOR_BGR2RGB))\n",
    "# print(trainY[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_active": false,
    "_cell_guid": "7dbff9b6-db78-a721-9245-03ceaa7085c0",
    "_uuid": "cba4811d592bfc78d40dd41b9d5d3dbe56d54507"
   },
   "source": [
    "**Keras CNN model, for example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/yanroo/anaconda3/envs/Keras/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/yanroo/anaconda3/envs/Keras/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/yanroo/anaconda3/envs/Keras/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/yanroo/anaconda3/envs/Keras/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/yanroo/anaconda3/envs/Keras/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/yanroo/anaconda3/envs/Keras/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 300, 300, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 300, 300, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 300, 300, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 150, 150, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 150, 150, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 150, 150, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 75, 75, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 75, 75, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 75, 75, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 75, 75, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 37, 37, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 37, 37, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 37, 37, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 37, 37, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 18, 18, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 41472)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              42468352  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 5125      \n",
      "=================================================================\n",
      "Total params: 57,188,165\n",
      "Trainable params: 57,188,165\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yanroo/anaconda3/envs/Keras/lib/python3.6/site-packages/keras/activations.py:235: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from keras.models import Model\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "\n",
    "# Transfer Learning from VGG16 architecture\n",
    "# Without fully-connected layers\n",
    "# define input shape as (224,224,3)\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(300,300,3))\n",
    "\n",
    "# Define our own fully-connected layers & output layer\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "\n",
    "x = Dense(1024, activation=LeakyReLU(alpha=0.1))(x)\n",
    "# x = Dropout(0.3)(x)\n",
    "\n",
    "preds = Dense(5, activation='linear')(x) #final layer with softmax activation\n",
    "\n",
    "\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=preds)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 300, 300, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 300, 300, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 300, 300, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 150, 150, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 150, 150, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 150, 150, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 75, 75, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 75, 75, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 75, 75, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 75, 75, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 37, 37, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 37, 37, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 37, 37, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 37, 37, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 18, 18, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 41472)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              42468352  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 5125      \n",
      "=================================================================\n",
      "Total params: 57,188,165\n",
      "Trainable params: 42,473,477\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers[:-3]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[-3:]:\n",
    "    layer.trainable = True\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2905d6b2-6db0-448e-892e-9d6489ee8408",
    "_execution_state": "idle",
    "_uuid": "6a33077d5e96d7b3d94d22b329b9b965545f56d8"
   },
   "source": [
    "full version model:\n",
    "\n",
    "    initial_model = applications.VGG16(weights=\"imagenet\", include_top=False, input_shape=(300,300,3))\n",
    "    last = initial_model.output\n",
    "    x = Flatten()(last)\n",
    "    x = Dense(1024)(x)\n",
    "    x = LeakyReLU(alpha=.1)(x)\n",
    "    preds = Dense(5, activation='linear')(x)\n",
    "    model = Model(initial_model.input, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_active": false,
    "_cell_guid": "be8659b0-304d-c197-b417-5183a81974f7",
    "_uuid": "111ff271d4d4f00d3435de4b3e018bf43bdd1e39"
   },
   "source": [
    "**Start training slowly :**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "58 training epochs is a example in the kernel. I train the new FC several epochs, observe the loss, then train more layers until the train loss close to 0.3. The total epochs before training the whole network is about 60(I think it is too slow due to my poor skill). And the whole network takes 27 epochs to got 0.126/0.247 train/validation loss with private LB 11.7.\n",
    " - 60 epoch before whole layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "\n",
    "\n",
    "callbacks = [ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, verbose=1),\n",
    "             EarlyStopping(monitor='val_loss', min_delta=0, patience=20, verbose=1),\n",
    "             ModelCheckpoint('./logs/VGG16' + 'ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5', monitor='val_loss', save_weights_only=True, save_best_only=True, period=3, verbose=1),\n",
    "             TensorBoard(log_dir='./logs/VGG16')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_active": false,
    "_cell_guid": "2048e2d0-f473-cb4f-7525-bbc3075717c2",
    "_execution_state": "idle",
    "_uuid": "a68c572bcefb5db3426285f6a28060a66057bfbe",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/yanroo/anaconda3/envs/Keras/lib/python3.6/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/yanroo/anaconda3/envs/Keras/lib/python3.6/site-packages/keras/callbacks.py:1122: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/yanroo/anaconda3/envs/Keras/lib/python3.6/site-packages/keras/callbacks.py:1125: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "Epoch 1/60\n",
      "1670/1670 [==============================] - 325s 195ms/step - loss: 5.0541 - val_loss: 2.1588\n",
      "Epoch 2/60\n",
      "1670/1670 [==============================] - 325s 194ms/step - loss: 1.7151 - val_loss: 1.8245\n",
      "Epoch 3/60\n",
      "1670/1670 [==============================] - 328s 197ms/step - loss: 1.5746 - val_loss: 1.5274\n",
      "\n",
      "Epoch 00003: val_loss improved from inf to 1.52739, saving model to ./logs/VGG16ep003-loss1.575-val_loss1.527.h5\n",
      "Epoch 4/60\n",
      "1670/1670 [==============================] - 323s 193ms/step - loss: 1.5071 - val_loss: 1.4413\n",
      "Epoch 5/60\n",
      "1670/1670 [==============================] - 320s 192ms/step - loss: 1.4276 - val_loss: 1.4425\n",
      "Epoch 6/60\n",
      "1670/1670 [==============================] - 311s 186ms/step - loss: 1.3744 - val_loss: 1.3819\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.52739 to 1.38186, saving model to ./logs/VGG16ep006-loss1.375-val_loss1.382.h5\n",
      "Epoch 7/60\n",
      "1670/1670 [==============================] - 320s 192ms/step - loss: 1.3582 - val_loss: 1.3203\n",
      "Epoch 8/60\n",
      "1670/1670 [==============================] - 325s 194ms/step - loss: 1.3199 - val_loss: 1.4108\n",
      "Epoch 9/60\n",
      "1670/1670 [==============================] - 313s 187ms/step - loss: 1.2850 - val_loss: 1.2710\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.38186 to 1.27096, saving model to ./logs/VGG16ep009-loss1.285-val_loss1.271.h5\n",
      "Epoch 10/60\n",
      "1670/1670 [==============================] - 325s 195ms/step - loss: 1.2848 - val_loss: 1.2426\n",
      "Epoch 11/60\n",
      "1670/1670 [==============================] - 322s 193ms/step - loss: 1.2513 - val_loss: 1.2121\n",
      "Epoch 12/60\n",
      "1670/1670 [==============================] - 318s 190ms/step - loss: 1.2410 - val_loss: 1.1988\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.27096 to 1.19878, saving model to ./logs/VGG16ep012-loss1.241-val_loss1.199.h5\n",
      "Epoch 13/60\n",
      "1670/1670 [==============================] - 310s 186ms/step - loss: 1.2099 - val_loss: 1.2611\n",
      "Epoch 14/60\n",
      "1670/1670 [==============================] - 325s 195ms/step - loss: 1.1903 - val_loss: 1.1877\n",
      "Epoch 15/60\n",
      "1670/1670 [==============================] - 323s 193ms/step - loss: 1.1848 - val_loss: 1.1523\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.19878 to 1.15234, saving model to ./logs/VGG16ep015-loss1.185-val_loss1.152.h5\n",
      "Epoch 16/60\n",
      "1670/1670 [==============================] - 324s 194ms/step - loss: 1.1841 - val_loss: 1.1737\n",
      "Epoch 17/60\n",
      "1670/1670 [==============================] - 327s 196ms/step - loss: 1.1742 - val_loss: 1.1503\n",
      "Epoch 18/60\n",
      "1670/1670 [==============================] - 325s 194ms/step - loss: 1.1819 - val_loss: 1.2383\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.15234\n",
      "Epoch 19/60\n",
      "1670/1670 [==============================] - 319s 191ms/step - loss: 1.1319 - val_loss: 1.0596\n",
      "Epoch 20/60\n",
      "1670/1670 [==============================] - 327s 196ms/step - loss: 1.1350 - val_loss: 1.1196\n",
      "Epoch 21/60\n",
      "1670/1670 [==============================] - 311s 186ms/step - loss: 1.1169 - val_loss: 1.1124\n",
      "\n",
      "Epoch 00021: val_loss improved from 1.15234 to 1.11236, saving model to ./logs/VGG16ep021-loss1.117-val_loss1.112.h5\n",
      "Epoch 22/60\n",
      "1670/1670 [==============================] - 323s 193ms/step - loss: 1.1202 - val_loss: 1.1617\n",
      "Epoch 23/60\n",
      "1670/1670 [==============================] - 324s 194ms/step - loss: 1.1189 - val_loss: 1.0895\n",
      "Epoch 24/60\n",
      "1670/1670 [==============================] - 322s 193ms/step - loss: 1.1226 - val_loss: 1.1152\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.11236\n",
      "Epoch 25/60\n",
      "1670/1670 [==============================] - 322s 193ms/step - loss: 1.1185 - val_loss: 1.1140\n",
      "Epoch 26/60\n",
      "1670/1670 [==============================] - 325s 194ms/step - loss: 1.0979 - val_loss: 1.1408\n",
      "Epoch 27/60\n",
      "1670/1670 [==============================] - 318s 191ms/step - loss: 1.0748 - val_loss: 1.0673\n",
      "\n",
      "Epoch 00027: val_loss improved from 1.11236 to 1.06732, saving model to ./logs/VGG16ep027-loss1.075-val_loss1.067.h5\n",
      "Epoch 28/60\n",
      "1670/1670 [==============================] - 320s 192ms/step - loss: 1.0750 - val_loss: 1.0838\n",
      "Epoch 29/60\n",
      "1670/1670 [==============================] - 326s 195ms/step - loss: 1.0664 - val_loss: 1.1496\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "Epoch 30/60\n",
      "1670/1670 [==============================] - 317s 190ms/step - loss: 1.0301 - val_loss: 1.0388\n",
      "\n",
      "Epoch 00030: val_loss improved from 1.06732 to 1.03882, saving model to ./logs/VGG16ep030-loss1.031-val_loss1.039.h5\n",
      "Epoch 31/60\n",
      "1670/1670 [==============================] - 325s 195ms/step - loss: 1.0289 - val_loss: 1.1512\n",
      "Epoch 32/60\n",
      "1670/1670 [==============================] - 318s 190ms/step - loss: 1.0351 - val_loss: 0.9374\n",
      "Epoch 33/60\n",
      "1670/1670 [==============================] - 310s 186ms/step - loss: 1.0241 - val_loss: 1.1057\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.03882\n",
      "Epoch 34/60\n",
      "1670/1670 [==============================] - 323s 193ms/step - loss: 1.0305 - val_loss: 1.0748\n",
      "Epoch 35/60\n",
      "1670/1670 [==============================] - 319s 191ms/step - loss: 1.0290 - val_loss: 1.1607\n",
      "Epoch 36/60\n",
      "1670/1670 [==============================] - 321s 192ms/step - loss: 1.0007 - val_loss: 1.1253\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1.03882\n",
      "Epoch 37/60\n",
      "1670/1670 [==============================] - 325s 195ms/step - loss: 1.0164 - val_loss: 1.0327\n",
      "Epoch 38/60\n",
      "1670/1670 [==============================] - 310s 185ms/step - loss: 1.0168 - val_loss: 1.0662\n",
      "Epoch 39/60\n",
      "1670/1670 [==============================] - 311s 186ms/step - loss: 1.0283 - val_loss: 1.1436\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1.03882\n",
      "Epoch 40/60\n",
      "1670/1670 [==============================] - 308s 184ms/step - loss: 1.0178 - val_loss: 0.9302\n",
      "Epoch 41/60\n",
      "1670/1670 [==============================] - 311s 186ms/step - loss: 1.0189 - val_loss: 1.1524\n",
      "Epoch 42/60\n",
      "1670/1670 [==============================] - 308s 184ms/step - loss: 0.9980 - val_loss: 1.0911\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.03882\n",
      "Epoch 43/60\n",
      "1670/1670 [==============================] - 319s 191ms/step - loss: 1.0225 - val_loss: 1.1551\n",
      "Epoch 44/60\n",
      "1670/1670 [==============================] - 309s 185ms/step - loss: 1.0167 - val_loss: 0.9740\n",
      "Epoch 45/60\n",
      "1670/1670 [==============================] - 310s 186ms/step - loss: 1.0306 - val_loss: 1.0722\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1.03882\n",
      "Epoch 46/60\n",
      "1670/1670 [==============================] - 327s 196ms/step - loss: 1.0099 - val_loss: 1.0922\n",
      "Epoch 47/60\n",
      "1670/1670 [==============================] - 317s 190ms/step - loss: 1.0182 - val_loss: 1.1224\n",
      "Epoch 48/60\n",
      "1670/1670 [==============================] - 314s 188ms/step - loss: 1.0155 - val_loss: 1.0579\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1.03882\n",
      "Epoch 49/60\n",
      "1670/1670 [==============================] - 319s 191ms/step - loss: 1.0028 - val_loss: 1.0899\n",
      "Epoch 50/60\n",
      "1670/1670 [==============================] - 308s 185ms/step - loss: 1.0367 - val_loss: 0.9958\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "Epoch 51/60\n",
      "1670/1670 [==============================] - 324s 194ms/step - loss: 1.0075 - val_loss: 1.1953\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 1.03882\n",
      "Epoch 52/60\n",
      "1670/1670 [==============================] - 307s 184ms/step - loss: 1.0022 - val_loss: 0.9908\n",
      "Epoch 53/60\n",
      "1670/1670 [==============================] - 307s 184ms/step - loss: 1.0157 - val_loss: 1.1858\n",
      "Epoch 54/60\n",
      "1670/1670 [==============================] - 319s 191ms/step - loss: 0.9874 - val_loss: 1.0158\n",
      "\n",
      "Epoch 00054: val_loss improved from 1.03882 to 1.01579, saving model to ./logs/VGG16ep054-loss0.988-val_loss1.016.h5\n",
      "Epoch 55/60\n",
      "1670/1670 [==============================] - 307s 184ms/step - loss: 1.0054 - val_loss: 1.0631\n",
      "Epoch 56/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1670/1670 [==============================] - 311s 186ms/step - loss: 1.0131 - val_loss: 1.0461\n",
      "Epoch 57/60\n",
      "1670/1670 [==============================] - 319s 191ms/step - loss: 1.0126 - val_loss: 1.1743\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 1.01579\n",
      "Epoch 58/60\n",
      "1670/1670 [==============================] - 319s 191ms/step - loss: 0.9978 - val_loss: 1.0480\n",
      "Epoch 59/60\n",
      "1670/1670 [==============================] - 315s 189ms/step - loss: 0.9939 - val_loss: 1.0409\n",
      "Epoch 60/60\n",
      "1670/1670 [==============================] - 316s 189ms/step - loss: 0.9997 - val_loss: 1.1297\n",
      "\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 1.01579\n",
      "Epoch 00060: early stopping\n"
     ]
    }
   ],
   "source": [
    "optim = keras.optimizers.SGD(lr=1e-4, momentum=0.2)\n",
    "model.compile(loss='mean_squared_error', optimizer=optim)\n",
    "\n",
    "\n",
    "step_size_train = train_generator.n // train_generator.batch_size\n",
    "step_size_val = validation_generator.n // validation_generator.batch_size\n",
    "\n",
    "history = model.fit_generator(generator=train_generator, steps_per_epoch=step_size_train,\n",
    "                              validation_data=validation_generator, validation_steps=step_size_val,\n",
    "                              epochs=60, verbose=1, callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_active": false,
    "_cell_guid": "9c85e582-becd-ed9f-a60d-3528e44911f5",
    "_uuid": "b0b83d9adbfb63591eb78a55b15fff104de083d2"
   },
   "source": [
    "**Then speed up :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 300, 300, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 300, 300, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 300, 300, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 150, 150, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 150, 150, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 150, 150, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 75, 75, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 75, 75, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 75, 75, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 75, 75, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 37, 37, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 37, 37, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 37, 37, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 37, 37, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 18, 18, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 41472)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              42468352  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 5125      \n",
      "=================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yanroo/anaconda3/envs/Keras/lib/python3.6/site-packages/keras/engine/training.py:493: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 50,108,741\n",
      "Trainable params: 42,473,477\n",
      "Non-trainable params: 7,635,264\n",
      "_________________________________________________________________\n",
      "Epoch 61/120\n",
      "1670/1670 [==============================] - 330s 198ms/step - loss: 1.3732 - val_loss: 0.8265\n",
      "Epoch 62/120\n",
      "1670/1670 [==============================] - 329s 197ms/step - loss: 1.0803 - val_loss: 0.7902\n",
      "Epoch 63/120\n",
      "1670/1670 [==============================] - 329s 197ms/step - loss: 0.9351 - val_loss: 0.9331\n",
      "\n",
      "Epoch 00063: val_loss improved from 1.01579 to 0.93314, saving model to ./logs/VGG16ep063-loss0.935-val_loss0.933.h5\n",
      "Epoch 64/120\n",
      "1670/1670 [==============================] - 322s 193ms/step - loss: 0.8510 - val_loss: 0.7293\n",
      "Epoch 65/120\n",
      "1670/1670 [==============================] - 325s 194ms/step - loss: 0.8237 - val_loss: 0.6504\n",
      "Epoch 66/120\n",
      "1670/1670 [==============================] - 326s 195ms/step - loss: 0.8522 - val_loss: 0.7072\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.93314 to 0.70721, saving model to ./logs/VGG16ep066-loss0.853-val_loss0.707.h5\n",
      "Epoch 67/120\n",
      "1670/1670 [==============================] - 322s 193ms/step - loss: 0.8440 - val_loss: 0.7036\n",
      "Epoch 68/120\n",
      "1670/1670 [==============================] - 323s 193ms/step - loss: 0.7843 - val_loss: 0.6178\n",
      "Epoch 69/120\n",
      "1670/1670 [==============================] - 327s 196ms/step - loss: 0.7855 - val_loss: 0.6263\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.70721 to 0.62633, saving model to ./logs/VGG16ep069-loss0.786-val_loss0.626.h5\n",
      "Epoch 70/120\n",
      "1670/1670 [==============================] - 320s 192ms/step - loss: 0.7389 - val_loss: 0.6464\n",
      "Epoch 71/120\n",
      "1670/1670 [==============================] - 323s 194ms/step - loss: 0.7139 - val_loss: 0.7130\n",
      "Epoch 72/120\n",
      "1670/1670 [==============================] - 327s 196ms/step - loss: 0.6937 - val_loss: 0.5895\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.62633 to 0.58953, saving model to ./logs/VGG16ep072-loss0.694-val_loss0.590.h5\n",
      "Epoch 73/120\n",
      "1670/1670 [==============================] - 317s 190ms/step - loss: 0.7493 - val_loss: 0.6846\n",
      "Epoch 74/120\n",
      "1670/1670 [==============================] - 311s 186ms/step - loss: 0.6721 - val_loss: 0.5890\n",
      "Epoch 75/120\n",
      "1670/1670 [==============================] - 328s 197ms/step - loss: 0.6743 - val_loss: 0.6813\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.58953\n",
      "Epoch 76/120\n",
      "1670/1670 [==============================] - 327s 196ms/step - loss: 0.6415 - val_loss: 0.5662\n",
      "Epoch 77/120\n",
      "1670/1670 [==============================] - 313s 187ms/step - loss: 0.6271 - val_loss: 0.4817\n",
      "Epoch 78/120\n",
      "1670/1670 [==============================] - 328s 196ms/step - loss: 0.5889 - val_loss: 0.6138\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.58953\n",
      "Epoch 79/120\n",
      "1670/1670 [==============================] - 330s 198ms/step - loss: 0.5919 - val_loss: 0.5028\n",
      "Epoch 80/120\n",
      "1670/1670 [==============================] - 324s 194ms/step - loss: 0.5769 - val_loss: 0.5872\n",
      "Epoch 81/120\n",
      "1670/1670 [==============================] - 315s 189ms/step - loss: 0.5566 - val_loss: 0.4864\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.58953 to 0.48636, saving model to ./logs/VGG16ep081-loss0.557-val_loss0.486.h5\n",
      "Epoch 82/120\n",
      "1670/1670 [==============================] - 323s 193ms/step - loss: 0.5625 - val_loss: 0.5238\n",
      "Epoch 83/120\n",
      "1670/1670 [==============================] - 323s 193ms/step - loss: 0.5729 - val_loss: 0.5627\n",
      "Epoch 84/120\n",
      "1670/1670 [==============================] - 324s 194ms/step - loss: 0.5756 - val_loss: 0.5535\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.48636\n",
      "Epoch 85/120\n",
      "1670/1670 [==============================] - 315s 189ms/step - loss: 0.5526 - val_loss: 0.5117\n",
      "Epoch 86/120\n",
      "1670/1670 [==============================] - 323s 193ms/step - loss: 0.5239 - val_loss: 0.5474\n",
      "Epoch 87/120\n",
      "1670/1670 [==============================] - 328s 196ms/step - loss: 0.5091 - val_loss: 0.5259\n",
      "\n",
      "Epoch 00087: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.48636\n",
      "Epoch 88/120\n",
      "1670/1670 [==============================] - 313s 187ms/step - loss: 0.5073 - val_loss: 0.4720\n",
      "Epoch 89/120\n",
      "1670/1670 [==============================] - 312s 187ms/step - loss: 0.4780 - val_loss: 0.5274\n",
      "Epoch 90/120\n",
      "1670/1670 [==============================] - 328s 196ms/step - loss: 0.4717 - val_loss: 0.5061\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.48636\n",
      "Epoch 91/120\n",
      "1670/1670 [==============================] - 327s 196ms/step - loss: 0.4548 - val_loss: 0.4642\n",
      "Epoch 92/120\n",
      "1670/1670 [==============================] - 322s 193ms/step - loss: 0.4538 - val_loss: 0.4380\n",
      "Epoch 93/120\n",
      "1670/1670 [==============================] - 324s 194ms/step - loss: 0.4468 - val_loss: 0.5116\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.48636\n",
      "Epoch 94/120\n",
      "1670/1670 [==============================] - 323s 194ms/step - loss: 0.4446 - val_loss: 0.4577\n",
      "Epoch 95/120\n",
      "1670/1670 [==============================] - 314s 188ms/step - loss: 0.4408 - val_loss: 0.4309\n",
      "Epoch 96/120\n",
      "1670/1670 [==============================] - 310s 186ms/step - loss: 0.4354 - val_loss: 0.5156\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.48636\n",
      "Epoch 97/120\n",
      "1670/1670 [==============================] - 324s 194ms/step - loss: 0.4306 - val_loss: 0.4785\n",
      "Epoch 98/120\n",
      "1670/1670 [==============================] - 313s 187ms/step - loss: 0.4282 - val_loss: 0.4975\n",
      "Epoch 99/120\n",
      "1670/1670 [==============================] - 315s 189ms/step - loss: 0.4296 - val_loss: 0.4967\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.48636\n",
      "Epoch 100/120\n",
      "1670/1670 [==============================] - 328s 196ms/step - loss: 0.4309 - val_loss: 0.4923\n",
      "Epoch 101/120\n",
      "1670/1670 [==============================] - 315s 188ms/step - loss: 0.4248 - val_loss: 0.5032\n",
      "Epoch 102/120\n",
      "1670/1670 [==============================] - 326s 195ms/step - loss: 0.4208 - val_loss: 0.4742\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.48636 to 0.47418, saving model to ./logs/VGG16ep102-loss0.421-val_loss0.474.h5\n",
      "Epoch 103/120\n",
      "1670/1670 [==============================] - 324s 194ms/step - loss: 0.4205 - val_loss: 0.5039\n",
      "Epoch 104/120\n",
      "1670/1670 [==============================] - 316s 189ms/step - loss: 0.4235 - val_loss: 0.4390\n",
      "Epoch 105/120\n",
      "1670/1670 [==============================] - 311s 186ms/step - loss: 0.4140 - val_loss: 0.4985\n",
      "\n",
      "Epoch 00105: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.47418\n",
      "Epoch 106/120\n",
      "1670/1670 [==============================] - 315s 188ms/step - loss: 0.4205 - val_loss: 0.4364\n",
      "Epoch 107/120\n",
      "1670/1670 [==============================] - 321s 192ms/step - loss: 0.4139 - val_loss: 0.5353\n",
      "Epoch 108/120\n",
      "1670/1670 [==============================] - 324s 194ms/step - loss: 0.4168 - val_loss: 0.4515\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.47418 to 0.45152, saving model to ./logs/VGG16ep108-loss0.417-val_loss0.452.h5\n",
      "Epoch 109/120\n",
      "1670/1670 [==============================] - 327s 196ms/step - loss: 0.4144 - val_loss: 0.5112\n",
      "Epoch 110/120\n",
      "1670/1670 [==============================] - 325s 194ms/step - loss: 0.4112 - val_loss: 0.4975\n",
      "Epoch 111/120\n",
      "1670/1670 [==============================] - 318s 191ms/step - loss: 0.4045 - val_loss: 0.4690\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.45152\n",
      "Epoch 112/120\n",
      "1670/1670 [==============================] - 324s 194ms/step - loss: 0.4138 - val_loss: 0.4909\n",
      "Epoch 113/120\n",
      "1670/1670 [==============================] - 314s 188ms/step - loss: 0.4049 - val_loss: 0.4355\n",
      "Epoch 114/120\n",
      "1670/1670 [==============================] - 324s 194ms/step - loss: 0.4037 - val_loss: 0.4783\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.45152\n",
      "Epoch 115/120\n",
      "1670/1670 [==============================] - 313s 187ms/step - loss: 0.4105 - val_loss: 0.4864\n",
      "\n",
      "Epoch 00115: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
      "Epoch 00115: early stopping\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers[:-7]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[-7:]:\n",
    "    layer.trainable = True\n",
    "model.summary()\n",
    "\n",
    "optim = keras.optimizers.SGD(lr=1e-4, momentum=0.9)\n",
    "model.compile(loss='mean_squared_error', optimizer=optim)\n",
    "\n",
    "\n",
    "history = model.fit_generator(generator=train_generator, steps_per_epoch=step_size_train,\n",
    "                              validation_data=validation_generator, validation_steps=step_size_val,\n",
    "                              initial_epoch=60, epochs=120, verbose=1, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 300, 300, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 300, 300, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 300, 300, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 150, 150, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 150, 150, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 150, 150, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 75, 75, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 75, 75, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 75, 75, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 75, 75, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 37, 37, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 37, 37, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 37, 37, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 37, 37, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 18, 18, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 41472)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              42468352  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 5125      \n",
      "=================================================================\n",
      "Total params: 49,552,901\n",
      "Trainable params: 49,552,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yanroo/anaconda3/envs/Keras/lib/python3.6/site-packages/keras/engine/training.py:493: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers[:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_active": false,
    "_cell_guid": "470ee712-89e8-3149-6a6a-863a1cb2c1be",
    "_execution_state": "idle",
    "_uuid": "8013099dbab26a4a57178bd95dd76aefdd45a0d1",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121/220\n",
      "1670/1670 [==============================] - 700s 419ms/step - loss: 0.6762 - val_loss: 0.5506\n",
      "Epoch 122/220\n",
      "1670/1670 [==============================] - 698s 418ms/step - loss: 0.4937 - val_loss: 0.4874\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.45152\n",
      "Epoch 123/220\n",
      "1670/1670 [==============================] - 698s 418ms/step - loss: 0.4640 - val_loss: 0.5248\n",
      "Epoch 124/220\n",
      "1670/1670 [==============================] - 701s 420ms/step - loss: 0.4416 - val_loss: 0.4774\n",
      "Epoch 125/220\n",
      "1670/1670 [==============================] - 702s 420ms/step - loss: 0.4275 - val_loss: 0.5070\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.45152\n",
      "Epoch 126/220\n",
      "1670/1670 [==============================] - 701s 420ms/step - loss: 0.4275 - val_loss: 0.4662\n",
      "Epoch 127/220\n",
      "1670/1670 [==============================] - 698s 418ms/step - loss: 0.4209 - val_loss: 0.5755\n",
      "Epoch 128/220\n",
      "1670/1670 [==============================] - 702s 420ms/step - loss: 0.4123 - val_loss: 0.4572\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.45152\n",
      "Epoch 129/220\n",
      "1670/1670 [==============================] - 701s 420ms/step - loss: 0.4340 - val_loss: 0.5441\n",
      "Epoch 130/220\n",
      "1670/1670 [==============================] - 702s 420ms/step - loss: 0.4184 - val_loss: 0.4783\n",
      "Epoch 131/220\n",
      "1670/1670 [==============================] - 700s 419ms/step - loss: 0.4016 - val_loss: 0.4927\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.45152\n",
      "Epoch 132/220\n",
      "1670/1670 [==============================] - 702s 420ms/step - loss: 0.4074 - val_loss: 0.4880\n",
      "Epoch 133/220\n",
      "1670/1670 [==============================] - 701s 420ms/step - loss: 0.4063 - val_loss: 0.4860\n",
      "Epoch 134/220\n",
      "1670/1670 [==============================] - 700s 419ms/step - loss: 0.3956 - val_loss: 0.5212\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.45152\n",
      "Epoch 135/220\n",
      "1670/1670 [==============================] - 701s 419ms/step - loss: 0.3824 - val_loss: 0.5199\n",
      "Epoch 136/220\n",
      "1670/1670 [==============================] - 697s 418ms/step - loss: 0.3967 - val_loss: 0.4634\n",
      "Epoch 137/220\n",
      "1670/1670 [==============================] - 701s 420ms/step - loss: 0.3908 - val_loss: 0.4860\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.45152\n",
      "Epoch 138/220\n",
      "1670/1670 [==============================] - 697s 418ms/step - loss: 0.3679 - val_loss: 0.4691\n",
      "\n",
      "Epoch 00138: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "Epoch 139/220\n",
      "1670/1670 [==============================] - 697s 417ms/step - loss: 0.3602 - val_loss: 0.4445\n",
      "Epoch 140/220\n",
      "1670/1670 [==============================] - 701s 420ms/step - loss: 0.3612 - val_loss: 0.4618\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.45152\n",
      "Epoch 141/220\n",
      "1670/1670 [==============================] - 701s 420ms/step - loss: 0.3545 - val_loss: 0.4565\n",
      "Epoch 142/220\n",
      "1670/1670 [==============================] - 702s 420ms/step - loss: 0.3560 - val_loss: 0.4598\n",
      "Epoch 143/220\n",
      "1670/1670 [==============================] - 702s 420ms/step - loss: 0.3585 - val_loss: 0.4745\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.45152\n",
      "Epoch 144/220\n",
      "1670/1670 [==============================] - 698s 418ms/step - loss: 0.3479 - val_loss: 0.4367\n",
      "Epoch 145/220\n",
      "1670/1670 [==============================] - 701s 419ms/step - loss: 0.3550 - val_loss: 0.4644\n",
      "Epoch 146/220\n",
      "1670/1670 [==============================] - 688s 412ms/step - loss: 0.3601 - val_loss: 0.5129\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.45152\n",
      "Epoch 147/220\n",
      "1670/1670 [==============================] - 698s 418ms/step - loss: 0.3524 - val_loss: 0.4090\n",
      "Epoch 148/220\n",
      "1670/1670 [==============================] - 701s 420ms/step - loss: 0.3518 - val_loss: 0.4662\n",
      "Epoch 149/220\n",
      "1670/1670 [==============================] - 701s 420ms/step - loss: 0.3564 - val_loss: 0.4747\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.45152\n",
      "Epoch 150/220\n",
      "1670/1670 [==============================] - 702s 421ms/step - loss: 0.3494 - val_loss: 0.4710\n",
      "Epoch 151/220\n",
      "1670/1670 [==============================] - 701s 420ms/step - loss: 0.3531 - val_loss: 0.4543\n",
      "Epoch 152/220\n",
      "1670/1670 [==============================] - 701s 420ms/step - loss: 0.3570 - val_loss: 0.4359\n",
      "\n",
      "Epoch 00152: val_loss improved from 0.45152 to 0.43589, saving model to ./logs/VGG16ep152-loss0.355-val_loss0.436.h5\n",
      "Epoch 153/220\n",
      "1670/1670 [==============================] - 701s 420ms/step - loss: 0.3594 - val_loss: 0.4650\n",
      "Epoch 154/220\n",
      "1670/1670 [==============================] - 698s 418ms/step - loss: 0.3521 - val_loss: 0.4749\n",
      "Epoch 155/220\n",
      "1670/1670 [==============================] - 700s 419ms/step - loss: 0.3505 - val_loss: 0.4933\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.43589\n",
      "Epoch 156/220\n",
      "1670/1670 [==============================] - 701s 420ms/step - loss: 0.3461 - val_loss: 0.4494\n",
      "Epoch 157/220\n",
      "1670/1670 [==============================] - 701s 420ms/step - loss: 0.3517 - val_loss: 0.4642\n",
      "\n",
      "Epoch 00157: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
      "Epoch 158/220\n",
      "1670/1670 [==============================] - 701s 420ms/step - loss: 0.3427 - val_loss: 0.4840\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.43589\n",
      "Epoch 159/220\n",
      "1670/1670 [==============================] - 701s 420ms/step - loss: 0.3451 - val_loss: 0.4298\n",
      "Epoch 160/220\n",
      "1670/1670 [==============================] - 701s 420ms/step - loss: 0.3446 - val_loss: 0.5119\n",
      "Epoch 161/220\n",
      "1670/1670 [==============================] - 702s 420ms/step - loss: 0.3494 - val_loss: 0.4456\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.43589\n",
      "Epoch 162/220\n",
      "1670/1670 [==============================] - 698s 418ms/step - loss: 0.3453 - val_loss: 0.4464\n",
      "Epoch 163/220\n",
      "1670/1670 [==============================] - 697s 418ms/step - loss: 0.3437 - val_loss: 0.4368\n",
      "Epoch 164/220\n",
      "1670/1670 [==============================] - 702s 420ms/step - loss: 0.3432 - val_loss: 0.4497\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.43589\n",
      "Epoch 165/220\n",
      "1670/1670 [==============================] - 697s 418ms/step - loss: 0.3433 - val_loss: 0.4674\n",
      "Epoch 166/220\n",
      "1670/1670 [==============================] - 701s 420ms/step - loss: 0.3457 - val_loss: 0.4827\n",
      "Epoch 167/220\n",
      "1670/1670 [==============================] - 702s 420ms/step - loss: 0.3397 - val_loss: 0.4195\n",
      "\n",
      "Epoch 00167: ReduceLROnPlateau reducing learning rate to 1.0000000116860975e-08.\n",
      "\n",
      "Epoch 00167: val_loss improved from 0.43589 to 0.41954, saving model to ./logs/VGG16ep167-loss0.340-val_loss0.420.h5\n",
      "Epoch 00167: early stopping\n"
     ]
    }
   ],
   "source": [
    "optim = keras.optimizers.SGD(lr=1e-5, momentum=0.9)\n",
    "model.compile(loss='mean_squared_error', optimizer=optim)\n",
    "# model.fit(trainX, trainY, epochs=30, verbose=2)\n",
    "history = model.fit_generator(generator=train_generator, steps_per_epoch=step_size_train,\n",
    "                              validation_data=validation_generator, validation_steps=step_size_val,\n",
    "                              initial_epoch=120, epochs=220, verbose=1, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_active": false,
    "_cell_guid": "e26e2efe-0b9d-8aef-6002-b9608acc8fd0",
    "_uuid": "d0715bf60eb4dcb1f87ff7f4b336fb47c29ff76e"
   },
   "source": [
    "**Test :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_active": false,
    "_cell_guid": "1cad34c2-c304-0b45-00f8-b4e892673f0c",
    "_execution_state": "idle",
    "_uuid": "1eb5b41bcf6d6cdc4647d88d4469d62cb3e42d31"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainX' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-5a453ce373b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#model.load_weights('./logs/ep110-loss0.648-val_loss1.099.h5')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training set --'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'    ground truth: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trainX' is not defined"
     ]
    }
   ],
   "source": [
    "# from keras.models import load_model\n",
    "# #model.load_weights('./logs/ep110-loss0.648-val_loss1.099.h5')\n",
    "\n",
    "# result = model.predict(trainX)\n",
    "# print('Training set --')\n",
    "# print('    ground truth: ', np.sum(trainY, axis=0))\n",
    "# print('  evaluate count: ', np.sum(result*(result>0.3), axis=0).astype('int'))\n",
    "\n",
    "# result = model.predict(valX)\n",
    "# print('Testing set --')\n",
    "# print('    ground truth: ', np.sum(valY, axis=0))\n",
    "# print('   predict count: ', np.sum(result*(result>0.3), axis=0).astype('int'))\n",
    "# print(result.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_active": false,
    "_cell_guid": "0ff05b53-abbf-cdb7-ea9b-635f1822da22",
    "_uuid": "ccb46c486dcb7dbe64a8b83b7e91f12f196e53e4"
   },
   "source": [
    "## Experience ##\n",
    "\n",
    "The challenge is scale problem. They distinguish sea lion by size. In different images, one juveniles is larger than adult_females in another.\n",
    "\n",
    "I can't handle it well, so I decided to fit LB score:\n",
    "\n",
    " - scale down testing image get better score\n",
    " - more juveniles (less adult_females) get better score\n",
    "\n",
    "The final submission is made by:\n",
    "\n",
    " - testing image scale: 0.48\n",
    " - add 50% juveniles, and subtract adult_females with the same amount\n",
    " - add 20% pups\n",
    "\n",
    "**Post processing details:**\n",
    "\n",
    "These lucky variables are according to patch level regression.\n",
    "\n",
    "The relationship between adult_females and juveniles in patches is:\n",
    "\n",
    "![juveniles regression][1]\n",
    "\n",
    " - value in table = average of juveniles# / (adult_females# + juveniles#) @ juveniles number range in patches\n",
    "\n",
    " - r#.# means image scale\n",
    "\n",
    " - *#.# means juveniles increase ratio\n",
    "\n",
    "  [1]: http://i.imgur.com/IkucSf6.gif"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Keras",
   "language": "python",
   "name": "keras"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
